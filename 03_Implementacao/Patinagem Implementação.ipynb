{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from time import time\n",
    "from cv2 import VideoCapture\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frame data\n",
      "Frame Data Collected\n",
      "Time spent collecting : 37.00911521911621\n",
      "Amount of frames collected : 2827\n"
     ]
    }
   ],
   "source": [
    "# faz a leitura de video e guarda todos os frames num array\n",
    "def load_frames(videoPath):\n",
    "    cap = VideoCapture(videoPath)\n",
    "    start = time()\n",
    "\n",
    "    \n",
    "    frameArray = []\n",
    "    print(\"Collecting frame data\")\n",
    "    while 1:\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            print(\"Frame Data Collected\")\n",
    "            break\n",
    "\n",
    "        target = frame[60:630, 380:1100]\n",
    "        frameArray.append(target)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27 or cv2.waitKey(1) == 113 or cv2.waitKey(1) == 81:\n",
    "            cap.release()\n",
    "            exit(0)\n",
    "            break\n",
    "\n",
    "\n",
    "    \n",
    "    end = time()\n",
    "    print(\"Time spent collecting : \" + str(end-start))\n",
    "    print(\"Amount of frames collected : \"+ str(len(frameArray)))\n",
    "    return frameArray   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza o método otsu equivalente cv2.threshold com a flag cv2.THRESH_OTSU no entanto é possivel obter\n",
    "# métricas que não são possiveis na função do OpenCV como\n",
    "def otsuThresh(components):\n",
    "    i= 0\n",
    "    bins_num = [180,255,255]\n",
    "    max_val = 0\n",
    "    thres = []\n",
    "    indexc = 0\n",
    "    for c in components:\n",
    "        # Get the image histogram\n",
    "        hist, bin_edges = np.histogram(c[400,:], bins=bins_num[i])\n",
    "        \n",
    "        # Get normalized histogram if it is required\n",
    "\n",
    "        hist = np.divide(hist.ravel(), hist.max())\n",
    "\n",
    "        # Calculate centers of bins\n",
    "        bin_mids = (bin_edges[:-1] + bin_edges[1:]) / 2.\n",
    "\n",
    "        # Iterate over all thresholds (indices) and get the probabilities w1(t), w2(t)\n",
    "        weight1 = np.cumsum(hist)\n",
    "        weight2 = np.cumsum(hist[::-1])[::-1]\n",
    "\n",
    "        # Get the class means mu0(t)\n",
    "        mean1 = np.cumsum(hist * bin_mids) / weight1\n",
    "        # Get the class means mu1(t)\n",
    "        mean2 = (np.cumsum((hist * bin_mids)[::-1]) / weight2[::-1])[::-1]\n",
    "\n",
    "        inter_class_variance = weight1[:-1] * weight2[1:] * (mean1[:-1] - mean2[1:]) ** 2\n",
    "\n",
    "        # Maximize the inter_class_variance function val\n",
    "        index_of_max_val = np.argmax(inter_class_variance)\n",
    "        #print(np.max(inter_class_variance))\n",
    "        if(max_val < np.max(inter_class_variance)):\n",
    "            max_val = np.max(inter_class_variance)\n",
    "            indexc = i\n",
    "            \n",
    "        i += 1\n",
    "        threshold = bin_mids[:-1][index_of_max_val]\n",
    "        #print(\"Otsu's algorithm implementation thresholding result: \", threshold)\n",
    "        thres.append(threshold)\n",
    "    return thres,indexc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertScale(img, alpha, beta):\n",
    "    \"\"\"Add bias and gain to an image with saturation arithmetics. Unlike\n",
    "    cv2.convertScaleAbs, it does not take an absolute value, which would lead to\n",
    "    nonsensical results (e.g., a pixel at 44 with alpha = 3 and beta = -210\n",
    "    becomes 78 with OpenCV, when in fact it should become 0).\n",
    "    \"\"\"\n",
    "\n",
    "    new_img = img * alpha + beta\n",
    "    new_img[new_img < 0] = 0\n",
    "    new_img[new_img > 255] = 255\n",
    "    return new_img.astype(np.uint8)\n",
    "\n",
    "# Automatic brightness and contrast optimization with optional histogram clipping\n",
    "def automatic_brightness_and_contrast(image, clip_hist_percent=25):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate grayscale histogram\n",
    "    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
    "    hist_size = len(hist)\n",
    "\n",
    "    # Calculate cumulative distribution from the histogram\n",
    "    accumulator = []\n",
    "    accumulator.append(float(hist[0]))\n",
    "    for index in range(1, hist_size):\n",
    "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
    "\n",
    "    # Locate points to clip\n",
    "    maximum = accumulator[-1]\n",
    "    clip_hist_percent *= (maximum/100.0)\n",
    "    clip_hist_percent /= 2.0\n",
    "\n",
    "    # Locate left cut\n",
    "    minimum_gray = 0\n",
    "    while accumulator[minimum_gray] < clip_hist_percent:\n",
    "        minimum_gray += 1\n",
    "\n",
    "    # Locate right cut\n",
    "    maximum_gray = hist_size -1\n",
    "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
    "        maximum_gray -= 1\n",
    "\n",
    "    # Calculate alpha and beta values\n",
    "    alpha = 255 / (maximum_gray - minimum_gray)\n",
    "    beta = -minimum_gray * alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "\t# build a lookup table mapping the pixel values [0, 255] to\n",
    "\t# their adjusted gamma values\n",
    "\tinvGamma = 1.0 / gamma\n",
    "\ttable = np.array([((i / 255.0) ** invGamma) * 255\n",
    "\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\t# apply gamma correction using the lookup table\n",
    "\treturn cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(videoPath,gamma = 1.0):\n",
    "    cap = VideoCapture(videoPath)\n",
    "    change = False\n",
    "    while 1:\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        target = frame[60:630, 380:1100]\n",
    "        \n",
    "        h = len(target)\n",
    "        start_height = h - 30\n",
    "      \n",
    "        target = adjust_gamma(target,gamma)\n",
    "        hsv = cv2.cvtColor(target,cv2.COLOR_BGR2HSV)\n",
    "        hue,saturation,value = cv2.split(hsv)\n",
    "        components = [hue,saturation,value]\n",
    "        thresholds,index = otsuThresh(components)\n",
    "        \n",
    "        if(index == 2):\n",
    "            grayFrame = cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
    "            guassianFrame = cv2.GaussianBlur(grayFrame,(5,5),cv2.BORDER_DEFAULT)\n",
    "            ret,thresh1 = cv2.threshold(guassianFrame,0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        else:\n",
    "            guassianFrame = cv2.GaussianBlur(components[index],(5,5),cv2.BORDER_DEFAULT)\n",
    "            ret,thresh1 =  cv2.threshold(guassianFrame,0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            \n",
    "        no_points_count = 0\n",
    "        \n",
    "        middlePixel = len(target[0])/2\n",
    "        \n",
    "        while(start_height > 0): \n",
    "            signed_thresh = thresh1[start_height].astype(np.int16) # select only one row\n",
    "            diff = np.diff(signed_thresh)   #The derivative of the start_height line\n",
    "\n",
    "            points = np.where(np.logical_or(diff > 200, diff < -200))\n",
    "\n",
    "            if len(points) > 0 and len(points[0]) > 1:\n",
    "                \n",
    "                middle = int((points[0][0] + points[0][1]) / 2)\n",
    "                \n",
    "                if((len(target[0])/2) - (middlePixel/10) < middle\n",
    "                   <= (len(target[0])/2) + (middlePixel/10) and start_height == h - 30):\n",
    "                    change = True\n",
    "                if( (len(target[0])/2) - (middlePixel/10)< middle\n",
    "                   <= (len(target[0])/2) + (middlePixel/10) and  change == True):\n",
    "                    color = (0,255,0)\n",
    "                    \n",
    "                if(change == False):\n",
    "                    color = (0,0,255)    \n",
    "                    \n",
    "                cv2.circle(target, (points[0][0], start_height), 5, (255,0,0), -1)\n",
    "                cv2.circle(target, (points[0][1], start_height), 5, (255,0,0), -1)\n",
    "                cv2.circle(target, (middle, start_height), 5, color, -1)\n",
    "                start_height -= 5\n",
    "                start_height = start_height % h\n",
    "            else:\n",
    "                start_height -= 5\n",
    "                start_height = start_height % h        \n",
    "                no_points_count += 1\n",
    "        \"\"\"\n",
    "        #CASO SE QUEIRA OBSERVAR AS IMAGENS DE CALIBRAÇÃO FAVOR DESCOMENTAR ESTE BLOCO:\n",
    "        plt.imshow(cv2.cvtColor(target,cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #E CASO QUEIRA OBSERVAR AS IMAGENS NUMA JANELA À PARTE DESCOMENTAR ESTE BLOCO:\n",
    "        cv2.imshow(\"calibration Video\",target)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \"\"\"\n",
    "        \n",
    "        change = False\n",
    "        \n",
    "        if cv2.waitKey(1) == 27 or cv2.waitKey(1) == 113 or cv2.waitKey(1) == 81:\n",
    "            cap.release()\n",
    "            exit(0)\n",
    "            \n",
    "            return index\n",
    "    cap.release()\n",
    "    exit(0)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,500)\n",
    "fontScale              = 2\n",
    "fontColor              = (0,0,255)\n",
    "lineType               = 2\n",
    "\n",
    "\n",
    "def lineAvaliation(image,middleLine):\n",
    "    middlePixel = len(image[0])/2\n",
    "    if(middlePixel < middleLine):\n",
    "        classification = 20 - round(middleLine / (middlePixel/10))\n",
    "    else:\n",
    "        classification = round(middleLine / (middlePixel/10))\n",
    "    \n",
    "        \n",
    "    return classification\n",
    "\n",
    "\n",
    "def processVideo(videoPath,index):\n",
    "    cap = VideoCapture(videoPath)\n",
    "    avaliations = []\n",
    "    while 1:\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        target = frame[60:630, 380:1100]\n",
    "        \n",
    "        h = len(target)\n",
    "        start_height = h - 30\n",
    "\n",
    "        if(index == 2):\n",
    "            grayFrame = cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
    "            ret,thresh1 = cv2.threshold(grayFrame,0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        else:\n",
    "            hsv = cv2.cvtColor(target,cv2.COLOR_BGR2HSV)\n",
    "            hue,saturation,value = cv2.split(hsv)\n",
    "            components = [hue,saturation,value]\n",
    "            ret,thresh1 = cv2.threshold(grayFrame,0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "        no_points_count = 0\n",
    "\n",
    "        while(start_height > 0): \n",
    "            signed_thresh = thresh1[start_height].astype(np.int16) # select only one row\n",
    "            diff = np.diff(signed_thresh)   #The derivative of the start_height line\n",
    "            \n",
    "            points = np.where(np.logical_or(diff > 200, diff < -200))\n",
    "\n",
    "            if len(points) > 0 and len(points[0]) > 1:\n",
    "                \n",
    "                middle = int((points[0][0] + points[0][1]) / 2)\n",
    "                value = None\n",
    "                if(start_height == h - 30):\n",
    "                    value = lineAvaliation(thresh1,middle)\n",
    "                    avaliations.append(value)\n",
    "                    \n",
    "                cv2.circle(target, (points[0][0], start_height), 5, (255,0,0), -1)\n",
    "                cv2.circle(target, (points[0][1], start_height), 5, (255,0,0), -1)\n",
    "                cv2.circle(target, (middle, start_height), 5, (0,0,255), -1)\n",
    "                if(value != None):\n",
    "                    cv2.putText(target,str(value), \n",
    "                        bottomLeftCornerOfText, \n",
    "                        font, \n",
    "                        fontScale,\n",
    "                        fontColor,\n",
    "                        lineType)\n",
    "                start_height -= 5\n",
    "                start_height = start_height % h\n",
    "            else:\n",
    "                start_height -= 5\n",
    "                start_height = start_height % h        \n",
    "                no_points_count += 1\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(target,cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        cv2.imshow(\"avaluation Video\",target)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \"\"\"\n",
    "        if cv2.waitKey(1) == 27 or cv2.waitKey(1) == 113 or cv2.waitKey(1) == 81:\n",
    "            cap.release()\n",
    "            exit(0)\n",
    "            break\n",
    "    \n",
    "    \n",
    "    cap.release()\n",
    "    exit(0)\n",
    "    return round(np.mean(avaliations))\n",
    "    \n",
    "index = calibration('./VideoContent/boa_amostra_preto3.mp4',1.0)\n",
    "print('calibration Done')\n",
    "processVideo('./VideoContent/muito_boa_amostra_preto_pouco_amarelo.mp4',index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
